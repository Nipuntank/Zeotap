{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zULkmwAOOMFc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv('Customers.csv')\n",
        "products = pd.read_csv('Products.csv')\n"
      ],
      "metadata": {
        "id": "A3uiWqpAORpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
        "customers['YearsSinceSignup'] = (pd.to_datetime('today') - customers['SignupDate']).dt.days / 365"
      ],
      "metadata": {
        "id": "7jEwaAgiOWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "region_encoded = encoder.fit_transform(customers[['Region']])\n",
        "region_df = pd.DataFrame(region_encoded, columns=encoder.get_feature_names_out(['Region']))"
      ],
      "metadata": {
        "id": "R0Kc3If8OxEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_features = pd.concat([customers[['CustomerID', 'YearsSinceSignup']], region_df], axis=1)"
      ],
      "metadata": {
        "id": "xsyBDGJ1O78K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_data = transactions.groupby('CustomerID').agg(\n",
        "    TotalSpent=('TotalValue', 'sum'),\n",
        "    NumTransactions=('TransactionID', 'count'),\n",
        "    AvgTransactionValue=('TotalValue', 'mean')\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "hkRKoFDlO_hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_data = pd.merge(customer_features, transaction_data, on='CustomerID')\n",
        "\n",
        "category_data = pd.get_dummies(transactions['ProductID'].map(products.set_index('ProductID')['Category']))\n"
      ],
      "metadata": {
        "id": "4eUvp-zePCCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_data['CustomerID'] = transactions['CustomerID']\n",
        "category_data = category_data.groupby('CustomerID').agg(lambda x: (x.astype(bool).any())).reset_index()  # Change this line\n",
        "\n",
        "full_data = pd.merge(customer_data, category_data, on='CustomerID')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "normalized_data = pd.DataFrame(scaler.fit_transform(full_data.drop('CustomerID', axis=1)), columns=full_data.columns[1:])\n",
        "cosine_sim = cosine_similarity(normalized_data)"
      ],
      "metadata": {
        "id": "E_UjwrznPE8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_lookalikes(customer_id, top_n=3):\n",
        "\n",
        "    if customer_id not in full_data['CustomerID'].values:\n",
        "        print(f\"Warning: Customer ID {customer_id} not found in data.\")\n",
        "        return []\n",
        "\n",
        "    customer_idx = full_data[full_data['CustomerID'] == customer_id].index[0]\n",
        "    similarity_scores = list(enumerate(cosine_sim[customer_idx]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    top_lookalikes = [(full_data.iloc[i[0]]['CustomerID'], i[1]) for i in similarity_scores[1:top_n+1]]  # Exclude the customer itself\n",
        "    return top_lookalikes"
      ],
      "metadata": {
        "id": "Sz-DEobaPTQp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookalikes = {}\n",
        "for customer_id in ['C0001', 'C0002', 'C0003', 'C0004', 'C0005', 'C0006', 'C0007', 'C0008', 'C0009', 'C0010',\n",
        "                    'C0011', 'C0012', 'C0013', 'C0014', 'C0015', 'C0016', 'C0017', 'C0018', 'C0019', 'C0020']:\n",
        "    lookalikes[customer_id] = get_top_lookalikes(customer_id)\n",
        "\n",
        "lookalikes_data = []\n",
        "for customer_id, lookalike_data in lookalikes.items():\n",
        "    if lookalike_data:\n",
        "        for lookalike_id, similarity_score in lookalike_data:\n",
        "            lookalikes_data.append([customer_id, lookalike_id, similarity_score])\n",
        "    else:\n",
        "        lookalikes_data.append([customer_id, np.nan, np.nan])\n",
        "\n",
        "lookalikes_df = pd.DataFrame(lookalikes_data, columns=['CustomerID', 'Lookalike_CustomerID', 'Similarity_Score'])\n",
        "lookalikes_df.to_csv('Lookalike.csv', index=False)  # Set index=False to avoid writing the index to the CSV\n",
        "\n",
        "print(lookalikes['C0001'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbToa5R4PW2C",
        "outputId": "8fa0ed6f-5cac-43b2-a463-d10e0426c95c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('C0152', 0.9968236860714906), ('C0174', 0.9780163559440436), ('C0004', 0.8332140770852455)]\n"
          ]
        }
      ]
    }
  ]
}